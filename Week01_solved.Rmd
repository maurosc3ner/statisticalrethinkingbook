---
title: "Week1"
author: "Esteban Correa"
date: "1/13/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
seed(123)
```

### Week 1

1. Suppose the globe tossing data (Chapter 2) had turned out to be 4 water
in 15 tosses. Construct the posterior distribution, using grid approximation.
Use the same flat prior as in the book.

```{r}
n=100
myGrid<-seq(from=0, to=1, length.out = n)

#Prior
myPrior<-rep(1,n)

# likelihood at each value of the grid
# Getting 3 tosses out of 3 with prob [0.0-1.0]
myLikelihood<-dbinom(4,15,prob = myGrid)
myLikelihood
# compute bayes rule without standardization
unstd.posterior<-myLikelihood*myPrior

# Standardized posterior
myPosterior<-unstd.posterior/sum(unstd.posterior)

# plot
par(mfrow=c(1,3))
plot(x=myGrid,y=myLikelihood,type="b")
plot(x=myGrid,y=myPrior,type="b")
plot(x=myGrid,y=myPosterior,type="b")
```


2. Start over in 1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earthâ€™s surface is water. What difference does the better prior make?

```{r}
# 1)W, W, W

n=100
myGrid<-seq(from=0, to=1, length.out = n)

#Prior
myPrior<-ifelse(myGrid>0.5,1,0)

# likelihood at each value of the grid
# Getting 3 tosses out of 3 with prob [0.0-1.0]
myLikelihood<-dbinom(4,15,prob = myGrid)
myLikelihood
# compute bayes rule without standardization
unstd.posterior<-myLikelihood*myPrior

# Standardized posterior
myPosterior<-unstd.posterior/sum(unstd.posterior)

# plot
par(mfrow=c(1,3))
plot(x=myGrid,y=myLikelihood,type="b")
plot(x=myGrid,y=myPrior,type="b")
plot(x=myGrid,y=myPosterior,type="b")

```

It shifts the mean to 0.5, but decreased pretty quickly because the current input of 4 W in 15 tosses.

3. For the posterior distribution from 2, compute 89% percentile and HPDI intervals. Compare the widths of these intervals. Which is wider? Why? If you had only the information in the interval, what might you misunderstand about the shape of the posterior distribution?

```{r}
# grid from zero to 1
p_grid<-seq(from=0, to=1, length.out = 1000)

# uniform prior
prob_p=ifelse(p_grid<0.5,0,1)

# 6 water from 9 tosses
prob_data<-dbinom(4,size = 15,prob=p_grid)

unstd_posterior<-prob_data*prob_p
#standarized
posterior<-unstd_posterior/sum(unstd_posterior)

# plot
par(mfrow=c(1,3))
plot(x=p_grid,y=prob_data,type="b")
plot(x=p_grid,y=prob_p,type="b")
plot(x=p_grid,y=posterior,type="b")

n_draws<-1e5
samples<-sample(p_grid, prob=posterior, size = n_draws, replace = T)
par(mfrow=c(1,2))
plot(samples,col="blue",ylim=c(0,1))
dens(samples,col="blue")

```

Which is wider? Why? If you had only the information in the interval, what might you misunderstand about the shape of the posterior distribution?

```{r}
PI(samples,prob=0.9)

# Highest posterior density interval
# Narrow interval containing the highest specified probability mass
HPDI(samples,prob=0.9)
```

PI is a wider interval. Because the highest values are concentrated around 50% and start to decay quickly, HPDI tends to be narrower. PI focused only in the percentiles whereas HPDI takes into account percentiles (x-axis) but also values or the "shape" (y-axis). PI is more data driven going blind style, no shape-skewness is taken into account.